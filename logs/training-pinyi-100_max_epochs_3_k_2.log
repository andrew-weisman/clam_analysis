
Load Dataset
label column: label_dummy
label dictionary: {'pole': 0, 'lcn': 1, 'p53': 2}
number of classes: 3
slide-level counts:  
 0    5
1    5
2    6
Name: label, dtype: int64
Patient-LVL; Number of samples registered in class 0: 5
Slide-LVL; Number of samples registered in class 0: 5
Patient-LVL; Number of samples registered in class 1: 5
Slide-LVL; Number of samples registered in class 1: 5
Patient-LVL; Number of samples registered in class 2: 6
Slide-LVL; Number of samples registered in class 2: 6
split_dir:  splits/idibell_100
################# Settings ###################
num_splits:  2
k_start:  -1
k_end:  -1
task:  idibell
max_epochs:  3
results_dir:  /home/weismanal/notebook/2021-11-11/testing_clam/results/pinyi/training
lr:  0.0002
experiment:  idibell_CLAM_100_max_epochs_3_k_2
reg:  1e-05
label_frac:  1.0
bag_loss:  ce
seed:  1
model_type:  clam_sb
model_size:  small
use_drop_out:  True
weighted_sample:  True
opt:  adam
bag_weight:  0.7
inst_loss:  svm
B:  8
split_dir:  splits/idibell_100

Training Fold 0!

Init train/val/test splits... 
Done!
Training on 4 samples
Validating on 6 samples
Testing on 6 samples

Init loss function... Done!

Init Model... Setting tau to 1.0
Done!
CLAM_SB(
  (attention_net): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Attn_Net_Gated(
      (attention_a): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Tanh()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_b): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Sigmoid()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_c): Linear(in_features=256, out_features=1, bias=True)
    )
  )
  (classifiers): Linear(in_features=512, out_features=3, bias=True)
  (instance_classifiers): ModuleList(
    (0): Linear(in_features=512, out_features=2, bias=True)
    (1): Linear(in_features=512, out_features=2, bias=True)
    (2): Linear(in_features=512, out_features=2, bias=True)
  )
  (instance_loss_fn): SmoothTop1SVM()
)
Total number of parameters: 792330
Total number of trainable parameters: 792330

Init optimizer ... Done!

Init Loaders... Done!

Setup EarlyStopping... Done!




class 0 clustering acc 0.34375: correct 33/96
class 1 clustering acc 0.78125: correct 25/32
Epoch: 0, train_loss: 1.1574, train_clustering_loss:  1.3269, train_error: 1.0000
class 0: acc 0.0, correct 0/1
class 1: acc 0.0, correct 0/2
class 2: acc 0.0, correct 0/1

Val Set, val_loss: 1.1099, val_error: 0.8333, auc: 0.3750
class 0 clustering acc 0.6944444444444444: correct 100/144
class 1 clustering acc 0.22916666666666666: correct 11/48
class 0: acc 0.0, correct 0/2
class 1: acc 0.5, correct 1/2
class 2: acc 0.0, correct 0/2
Validation loss decreased (inf --> 1.109945).  Saving model ...




class 0 clustering acc 0.8333333333333334: correct 80/96
class 1 clustering acc 0.21875: correct 7/32
Epoch: 1, train_loss: 1.0767, train_clustering_loss:  1.2592, train_error: 0.2500
class 0: acc 0.0, correct 0/1
class 1: acc 1.0, correct 2/2
class 2: acc 1.0, correct 1/1

Val Set, val_loss: 1.1158, val_error: 0.6667, auc: 0.3750
class 0 clustering acc 1.0: correct 144/144
class 1 clustering acc 0.0: correct 0/48
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
EarlyStopping counter: 1 out of 20




class 0 clustering acc 0.96875: correct 93/96
class 1 clustering acc 0.0: correct 0/32
Epoch: 2, train_loss: 1.0778, train_clustering_loss:  1.2116, train_error: 0.7500
class 0: acc 0.0, correct 0/1
class 1: acc 1.0, correct 1/1
class 2: acc 0.0, correct 0/2

Val Set, val_loss: 1.1223, val_error: 0.6667, auc: 0.3750
class 0 clustering acc 1.0: correct 144/144
class 1 clustering acc 0.0: correct 0/48
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
EarlyStopping counter: 2 out of 20
Val error: 0.8333, ROC AUC: 0.3750
Test error: 0.5000, ROC AUC: 0.7500
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.5, correct 1/2

Training Fold 1!

Init train/val/test splits... 
Done!
Training on 4 samples
Validating on 6 samples
Testing on 6 samples

Init loss function... Done!

Init Model... Setting tau to 1.0
Done!
CLAM_SB(
  (attention_net): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.25, inplace=False)
    (3): Attn_Net_Gated(
      (attention_a): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Tanh()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_b): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Sigmoid()
        (2): Dropout(p=0.25, inplace=False)
      )
      (attention_c): Linear(in_features=256, out_features=1, bias=True)
    )
  )
  (classifiers): Linear(in_features=512, out_features=3, bias=True)
  (instance_classifiers): ModuleList(
    (0): Linear(in_features=512, out_features=2, bias=True)
    (1): Linear(in_features=512, out_features=2, bias=True)
    (2): Linear(in_features=512, out_features=2, bias=True)
  )
  (instance_loss_fn): SmoothTop1SVM()
)
Total number of parameters: 792330
Total number of trainable parameters: 792330

Init optimizer ... Done!

Init Loaders... Done!

Setup EarlyStopping... Done!




class 0 clustering acc 0.3333333333333333: correct 32/96
class 1 clustering acc 0.75: correct 24/32
Epoch: 0, train_loss: 1.1349, train_clustering_loss:  1.3319, train_error: 0.5000
class 0: acc 0.0, correct 0/1
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/1

Val Set, val_loss: 1.1075, val_error: 0.6667, auc: 0.7500
class 0 clustering acc 0.4236111111111111: correct 61/144
class 1 clustering acc 0.6041666666666666: correct 29/48
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
Validation loss decreased (inf --> 1.107467).  Saving model ...




class 0 clustering acc 0.65625: correct 63/96
class 1 clustering acc 0.75: correct 24/32
Epoch: 1, train_loss: 0.9432, train_clustering_loss:  1.2430, train_error: 0.2500
class 0: acc 0.0, correct 0/1
class 1: acc 1.0, correct 3/3
class 2: acc None, correct 0/0

Val Set, val_loss: 1.1166, val_error: 0.6667, auc: 0.6667
class 0 clustering acc 0.7083333333333334: correct 102/144
class 1 clustering acc 0.16666666666666666: correct 8/48
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
EarlyStopping counter: 1 out of 20




class 0 clustering acc 0.8854166666666666: correct 85/96
class 1 clustering acc 0.15625: correct 5/32
Epoch: 2, train_loss: 1.1944, train_clustering_loss:  1.2298, train_error: 0.7500
class 0: acc 0.0, correct 0/1
class 1: acc 1.0, correct 1/1
class 2: acc 0.0, correct 0/2

Val Set, val_loss: 1.1240, val_error: 0.6667, auc: 0.6667
class 0 clustering acc 1.0: correct 144/144
class 1 clustering acc 0.0: correct 0/48
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
EarlyStopping counter: 2 out of 20
Val error: 0.6667, ROC AUC: 0.7500
Test error: 0.6667, ROC AUC: 0.2083
class 0: acc 0.0, correct 0/2
class 1: acc 1.0, correct 2/2
class 2: acc 0.0, correct 0/2
finished!
end script
